{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/scratch2/ttoebro/data/X_train_rad41.npy')\n",
    "Y = np.load('/scratch2/ttoebro/data/Y_train_rad41.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(tensor_in, name_layer, is_training, f_num, f_size):\n",
    "    x = tf.layers.conv2d(\n",
    "        inputs = tensor_in,\n",
    "        filters = f_num,\n",
    "        kernel_size = [f_size, f_size],\n",
    "        padding = \"same\",\n",
    "        activation= None,\n",
    "        name = name_layer,\n",
    "        use_bias=False)\n",
    "    \n",
    "    x = tf.layers.batch_normalization(x, name = name_layer + \"_bn\",\n",
    "                                             center=True, \n",
    "                                             scale=True, \n",
    "                                             training=is_training)\n",
    "    \n",
    "    return tf.nn.relu(x, name = name_layer + \"_relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Execute_model(depth, filter_num, loss_scheme, skipped_scheme, filter_size, learning_rate, directory, name, steps):\n",
    "    # Check arguments\n",
    "    if (depth < 1 or depth > 40):\n",
    "        raise Exception('Depth of {} is not allowed!'.format(depth))\n",
    "    if(filter_num < 1 or filter_num > 256):\n",
    "        raise Exception('filter_num of {} is not allowed!'.format(filter_num))\n",
    "    if(not (loss_scheme == \"L1\" or loss_scheme == \"L2\" or loss == \"SSIM\")):\n",
    "        raise Exception('loss_scheme {} is not allowed!'.format(loss_scheme))\n",
    "    if(not (skipped_scheme == 'DnCNN' or skipped_scheme == 'ResNet')):\n",
    "        raise Exception('skipped_scheme {} is not allowed!'.format(skipped_scheme))\n",
    "    if(filter_size < 1 or filter_size > 9):\n",
    "        raise Exception('filter_size of {} is not allowed!'.format(filter_size))\n",
    "    if(learning_rate < 0 or learning_rate > 1):\n",
    "        raise Exception('learning_rate of {} is not allowed!'.format(learning_rate))\n",
    "    \n",
    "    ## run model ##\n",
    "    start = time.time()\n",
    "    print('Model is run!')\n",
    "    \n",
    "    Runtime_train = time.time() - start\n",
    "    \n",
    "    ## evaluate model ##\n",
    "    start = time.time()\n",
    "    print('Model is evaluated')\n",
    "        \n",
    "    Runtime_test = time.time() - start\n",
    "    \n",
    "    # These have to be extracted from model eval!\n",
    "    MAE = -2\n",
    "    MSE = -2\n",
    "    SSIM = -2 \n",
    "    \n",
    "    # return MAE, MSE, SSIM on test and run-time\n",
    "    return({'MAE': MAE, 'MSE': MSE, 'SSIM' : SSIM, 'Runtime_test' : Runtime_test, 'Runtime_train' : Runtime_train})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate of 200 is not allowed!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    Execute_model(3, 3, \"L1\", \"DnCNN\", 3, 200)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutoEncoder_model(features, labels, mode):\n",
    "   # Input Layer\n",
    "    input_layer = features['x']\n",
    "    \n",
    "    # Paramter for Grid_search:\n",
    "    depth = depth_in\n",
    "    filter_num = filter_num_in\n",
    "    loss = loss_in\n",
    "    skipped_scheme = skipped_scheme_in\n",
    "    filter_size = filter_size_in\n",
    "    learning_rate = learning_rate_in\n",
    "    tb = tb_in # Should tensorboard summaries be created?\n",
    "    \n",
    "    # Convolutional layer #1     \n",
    "    input_layer = tf.layers.conv2d(\n",
    "        inputs = input_layer,\n",
    "        filters = 64,\n",
    "        kernel_size = 3,\n",
    "        padding = \"same\",\n",
    "        activation= tf.nn.relu,\n",
    "        name = \"Conv_Init\")\n",
    "    is_training_mode = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    if (skipped_scheme == \"ResNet\"):\n",
    "         # Standard DnCNN skipped layers scheme: one residual link between first and last\n",
    "        cur_tensor = input_layer\n",
    "        for i in range(1, depth + 1):\n",
    "            if i == 1:\n",
    "            cur_tensor = conv_layer(cur_tensor, \"conv{}\".format(i), is_training = is_training_mode, filter_num, filter_size)\n",
    "            save = cur_tensor\n",
    "            elif (i - 1) % 2 == 0:\n",
    "                cur_tensor = conv_layer(cur_tensor + save \"conv{}\".format(i), is_training = is_training_mode, filter_num, filter_size)\n",
    "                save = cur_tensor\n",
    "            else:\n",
    "                cur_tensor = conv_layer(cur_tensor + save \"conv{}\".format(i), is_training = is_training_mode, filter_num, filter_size)\n",
    "                \n",
    "        # Final layers: Make it a gray scale image again!\n",
    "        if (i - 1) % 2 == 0:\n",
    "            final_layer = tf.layers.conv2d(\n",
    "                inputs = cur_tensor + save,\n",
    "                filters = 1,\n",
    "                kernel_size = [1, 1],\n",
    "                padding = \"same\",\n",
    "                activation = None,\n",
    "                name = \"final_layer\")\n",
    "        else:\n",
    "            final_layer = tf.layers.conv2d(\n",
    "                inputs = cur_tensor,\n",
    "                filters = 1,\n",
    "                kernel_size = [1, 1],\n",
    "                padding = \"same\",\n",
    "                activation = None,\n",
    "                name = \"final_layer\")\n",
    "    else:\n",
    "        # Standard DnCNN skipped layers scheme: one residual link between first and last\n",
    "        cur_tensor = input_layer\n",
    "        for i in range(1, depth + 1):\n",
    "            cur = conv_layer(cur_tensor, \"conv{}\".format(i), is_training = is_training_mode, filter_num, filter_size)\n",
    "\n",
    "        # Final layers: Make it a gray scale image again!\n",
    "        final_layer = tf.layers.conv2d(\n",
    "            inputs = cur_tensor,\n",
    "            filters = 1,\n",
    "            kernel_size = [1, 1],\n",
    "            padding = \"same\",\n",
    "            activation = None,\n",
    "            name = \"final_layer\") + input_layer\n",
    "      \n",
    "    # Give output in prediction mode\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions=final_layer)\n",
    "\n",
    "    # Calulate loss function according to loss_scheme\n",
    "    if(loss_scheme == 'SSIM'):\n",
    "        loss = -tf.reduce_mean(tf.image.ssim(labels, final_layer, 1.0))\n",
    "    elif(loss_scheme == 'L1'):\n",
    "        loss = tf.losses.mean_squared_error(labels = labels , predictions = final_layer)\n",
    "    else:\n",
    "        loss =  loss = tf.losses.absolute_difference(labels = labels , predictions = final_layer)\n",
    "    \n",
    "        \n",
    "    ### Print summary ###\n",
    "    if (mode != tf.estimator.ModeKeys.PREDICT && tb):\n",
    "        tf.summary.image(\"Input_Image\", input_layer, max_outputs = 1)\n",
    "        tf.summary.image(\"Output_Image\", final_layer, max_outputs = 1)\n",
    "        tf.summary.image(\"True_Image\", labels,  max_outputs = 1)\n",
    "        tf.summary.histogram(\"Summary_final_layer\", final_layer)\n",
    "        tf.summary.histogram(\"Summary_labels\", labels)\n",
    "        tf.summary.scalar(\"Value_Loss_Function\", loss)\n",
    "        \n",
    "        # Besides the specific ones write out all trainiable variables\n",
    "        for var in tf.trainable_variables():\n",
    "            name = var.name\n",
    "            name = name.replace(':', '_')\n",
    "            tf.summary.histogram(name, var)\n",
    "            \n",
    "        # Finally merge the summary\n",
    "        merged_summary = tf.summary.merge_all()\n",
    "\n",
    "    # Specify Learning \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        # This is needed so that Batch normalization paramters are trained as well.\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            # Specify the Optimizer\n",
    "            original_optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "            # Use gradient clipping to avoid exploding gradients\n",
    "            optimizer = tf.contrib.estimator.clip_gradients_by_norm(original_optimizer, clip_norm=5.0)\n",
    "            # The loss function should be minimized.\n",
    "            train_op = optimizer.minimize(loss = loss, global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/scratch2/ttoebro/models/DnCNN_V6', '_tf_random_seed': None, '_save_summary_steps': 5, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f568c734400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "runconf = tf.estimator.RunConfig(save_summary_steps=5, log_step_count_steps = 10)\n",
    "\n",
    "AutoEncoder = tf.estimator.Estimator(config=runconf,\n",
    "    model_fn=AutoEncoder_model, model_dir= \"/scratch2/ttoebro/models/DnCNN_V6\")\n",
    "\n",
    "\n",
    "train = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X},\n",
    "    y=Y,\n",
    "    batch_size=8,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let it run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /scratch2/ttoebro/models/DnCNN_V6/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2 into /scratch2/ttoebro/models/DnCNN_V6/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0001380602, step = 2\n",
      "INFO:tensorflow:Saving checkpoints for 8 into /scratch2/ttoebro/models/DnCNN_V6/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.00952361\n",
      "INFO:tensorflow:loss = 0.43026507, step = 12 (1050.038 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14 into /scratch2/ttoebro/models/DnCNN_V6/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 20 into /scratch2/ttoebro/models/DnCNN_V6/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.00954452\n",
      "INFO:tensorflow:loss = 0.54139984, step = 22 (1047.720 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26 into /scratch2/ttoebro/models/DnCNN_V6/model.ckpt.\n"
     ]
    }
   ],
   "source": [
    "AutoEncoder.train(\n",
    "    input_fn=train,\n",
    "    steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
